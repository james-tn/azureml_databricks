{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/ml-frameworks/scikit-learn/train-hyperparameter-tune-deploy-with-sklearn/train-hyperparameter-tune-deploy-with-sklearn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting together into a pipelie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Go through the [Configuration](../../../../configuration.ipynb) notebook to install the Azure Machine Learning Python SDK and create an Azure ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.16.0\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opt-in diagnostics for better experience, quality, and security of future releases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: ws01ent\n",
      "Azure region: westus2\n",
      "Subscription id: 0e9bace8-7a81-4922-83b5-d995ff706507\n",
      "Resource group: azureml\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AmlCompute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, we use Azure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)) for our remote training compute resource.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we could not find the cluster with the given name, then we will create a new cluster here. We will create an `AmlCompute` cluster of `STANDARD_D2_V2` CPU VMs. This process is broken down into 3 steps:\n",
    "1. create the configuration (this step is local and only takes a second)\n",
    "2. create the cluster (this step will take about **20 seconds**)\n",
    "3. provision the VMs to bring the cluster to the initial size (of 1 in this case). This step will take about **3-5 minutes** and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-10-26T18:21:05.010000+00:00', 'errors': None, 'creationTime': '2020-10-26T15:36:47.471716+00:00', 'modifiedTime': '2020-10-26T16:38:11.338154+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT1200S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D12_V2'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cluster-train\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D12_V2', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code retrieves a CPU compute target. Scikit-learn does not support GPU computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on the remote compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have your data and training script prepared, you are ready to train on your remote compute. You can take advantage of Azure compute to leverage a CPU cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './train'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will need to create your training script. In this tutorial, the training script is already provided for you at `train_iris`.py. In practice, you should be able to take any custom training script as is and run it with Azure ML without having to modify your code.\n",
    "\n",
    "However, if you would like to use Azure ML's [tracking and metrics](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#metrics) capabilities, you will have to add a small amount of Azure ML code inside your training script.\n",
    "\n",
    "In `train_iris.py`, we will log some metrics to our Azure ML run. To do so, we will access the Azure ML Run object within the script:\n",
    "\n",
    "```python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "\n",
    "Further within `train_iris.py`, we log the kernel and penalty parameters, and the highest accuracy the model achieves:\n",
    "\n",
    "```python\n",
    "run.log('Kernel type', np.string(args.kernel))\n",
    "run.log('Penalty', np.float(args.penalty))\n",
    "\n",
    "run.log('Accuracy', np.float(accuracy))\n",
    "```\n",
    "\n",
    "These run metrics will become particularly important when we begin hyperparameter tuning our model in the \"Tune model hyperparameters\" section.\n",
    "\n",
    "Once your script is ready, copy the training script `train_iris.py` into your project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this Scikit-learn tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'train_isd'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an environment\n",
    "\n",
    "Define a conda environment YAML file with your training script dependencies and create an Azure ML environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conda_dependencies.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda_dependencies.yml\n",
    "\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- pip:\n",
    "  - azureml-defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "sklearn_env = Environment.from_conda_specification(name = 'sklearn-env', file_path = './conda_dependencies.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the training job\n",
    "\n",
    "Create a ScriptRunConfig object to specify the configuration details of your training job, including your training script, environment to use, and the compute target to run on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "estimator = Estimator(source_directory=project_folder,\n",
    "                      entry_script='train_isd.py',\n",
    "                      compute_target=compute_target,\n",
    "                      environment_definition=sklearn_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your experiment by submitting your ScriptRunConfig object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen how to do a simple Scikit-learn training run using the SDK, let's see if we can further improve the accuracy of our model. We can optimize our model's hyperparameters using Azure Machine Learning's hyperparameter tuning capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a hyperparameter sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will define the hyperparameter space to sweep over. Let's tune the `kernel` and `penalty` parameters. In this example we will use random sampling to try different configuration sets of hyperparameters to maximize our primary metric, `Accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\n",
    "    \n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "    \"--max_features\": choice('sqrt', 'log2'),\n",
    "    \"--n_estimators\": choice(100, 200, 500)\n",
    "    }\n",
    ")\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(estimator=estimator,\n",
    "                                     hyperparameter_sampling=param_sampling, \n",
    "                                     primary_metric_name='MSE',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n",
    "                                     max_total_runs=12,\n",
    "                                     max_concurrent_runs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps.python_script_step import PythonScriptStep \n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "\n",
    "metrics_output_name = 'metrics_output'\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                             datastore=datastore,\n",
    "                             pipeline_output_name=metrics_output_name)\n",
    "\n",
    "hd_step_name='hyper_param_training'\n",
    "\n",
    "hd_step = HyperDriveStep(\n",
    "    name=hd_step_name,\n",
    "    hyperdrive_config=hyperdrive_config,\n",
    "    estimator_entry_script_arguments=['--dataset_name', 'ISDWeatherDS'],\n",
    "    metrics_output=metrics_data)\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "\n",
    "# enable Docker \n",
    "run_config.environment.docker.enabled = True\n",
    "\n",
    "# set Docker base image to the default CPU-based image\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "\n",
    "# use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# specify CondaDependencies obj\n",
    "run_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn', 'pandas'], pip_packages = [ 'azureml-sdk','azureml-dataprep[pandas]'])\n",
    "\n",
    "\n",
    "model_reg_step = PythonScriptStep(script_name = \"test_register_model.py\", name=\"test_register_model\", \n",
    "                                  arguments=['--dataset_name', 'ISDWeatherDS','--hd_step_name', hd_step_name], \n",
    "                                  compute_target=compute_target, source_directory=project_folder, runconfig=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step hyper_param_training [c0a88a38][4cc4e7c3-bff6-4c3d-8a32-05d358bdc767], (This step is eligible to reuse a previous run's output)Created step test_register_model [70392e58][2c6ded23-7dd4-42ef-b44c-5a42829663f2], (This step is eligible to reuse a previous run's output)\n",
      "\n",
      "Submitted PipelineRun a142c6be-3f7b-45a2-849a-87151350cfab\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/train_isd/runs/a142c6be-3f7b-45a2-849a-87151350cfab?wsid=/subscriptions/0e9bace8-7a81-4922-83b5-d995ff706507/resourcegroups/azureml/workspaces/ws01ent\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline, StepSequence\n",
    "\n",
    "step_sequence = StepSequence(steps=[hd_step, model_reg_step])\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=step_sequence)\n",
    "pipeline_run = experiment.submit(pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lauch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can monitor the progress of the runs with the following Jupyter widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c71b46792984c7db39278c899253b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/train_isd/runs/a142c6be-3f7b-45a2-849a-87151350cfab?wsid=/subscriptions/0e9bace8-7a81-4922-83b5-d995ff706507/resourcegroups/azureml/workspaces/ws01ent\", \"run_id\": \"a142c6be-3f7b-45a2-849a-87151350cfab\", \"run_properties\": {\"run_id\": \"a142c6be-3f7b-45a2-849a-87151350cfab\", \"created_utc\": \"2020-10-26T19:23:58.155337Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2020-10-26T19:32:11.490223Z\", \"status\": \"Failed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.a142c6be-3f7b-45a2-849a-87151350cfab/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=MnpxYnmgH4x2zShkJEVk3SqEE1hOdXAlsjvwmxsoea8%3D&st=2020-10-27T03%3A18%3A34Z&se=2020-10-27T11%3A28%3A34Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.a142c6be-3f7b-45a2-849a-87151350cfab/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=H5FcNPzGGpFIvk%2BSm4c8hmsGzJMq6clVSvLYvT8Yqd8%3D&st=2020-10-27T03%3A18%3A34Z&se=2020-10-27T11%3A28%3A34Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.a142c6be-3f7b-45a2-849a-87151350cfab/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=oig6wX3tCEn31G%2BLNjJx6SGIy1jDs0AiPmKumzU5mgc%3D&st=2020-10-27T03%3A18%3A34Z&se=2020-10-27T11%3A28%3A34Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:08:13\"}, \"child_runs\": [{\"run_id\": \"3002f270-c4a2-48fe-b147-cb99ee3b1b9e\", \"name\": \"hyper_param_training\", \"status\": \"Finished\", \"start_time\": \"2020-10-26T19:24:18.391031Z\", \"created_time\": \"2020-10-26T19:24:18.391031Z\", \"end_time\": \"2020-10-26T19:24:18.509679Z\", \"duration\": \"0:00:00\", \"run_number\": 50, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-10-26T19:24:18.391031Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"d8474101-bc22-46de-a1f3-375e4bb43370\", \"name\": \"test_register_model\", \"status\": \"Failed\", \"start_time\": \"2020-10-26T19:30:06.502861Z\", \"created_time\": \"2020-10-26T19:24:19.286051Z\", \"end_time\": \"2020-10-26T19:32:06.4894Z\", \"duration\": \"0:07:47\", \"run_number\": 51, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-10-26T19:24:19.286051Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-10-26 19:24:18Z] Completing processing run id 3002f270-c4a2-48fe-b147-cb99ee3b1b9e.\\n[2020-10-26 19:24:19Z] Submitting 1 runs, first five are: 70392e58:d8474101-bc22-46de-a1f3-375e4bb43370\\n[2020-10-26 19:32:11Z] Execution of experiment failed, update experiment status and cancel running nodes.\\n\", \"graph\": {\"datasource_nodes\": {}, \"module_nodes\": {\"c0a88a38\": {\"node_id\": \"c0a88a38\", \"name\": \"hyper_param_training\", \"status\": \"Finished\", \"_is_reused\": true, \"run_id\": \"3002f270-c4a2-48fe-b147-cb99ee3b1b9e\"}, \"70392e58\": {\"node_id\": \"70392e58\", \"name\": \"test_register_model\", \"status\": \"Failed\", \"_is_reused\": false, \"run_id\": \"d8474101-bc22-46de-a1f3-375e4bb43370\"}}, \"edges\": [{\"source_node_id\": \"c0a88a38\", \"source_node_name\": \"hyper_param_training\", \"source_name\": \"metrics_data\", \"target_name\": \"_run_after_input_0\", \"dst_node_id\": \"70392e58\", \"dst_node_name\": \"test_register_model\"}], \"child_runs\": [{\"run_id\": \"3002f270-c4a2-48fe-b147-cb99ee3b1b9e\", \"name\": \"hyper_param_training\", \"status\": \"Finished\", \"start_time\": \"2020-10-26T19:24:18.391031Z\", \"created_time\": \"2020-10-26T19:24:18.391031Z\", \"end_time\": \"2020-10-26T19:24:18.509679Z\", \"duration\": \"0:00:00\", \"run_number\": 50, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-10-26T19:24:18.391031Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"d8474101-bc22-46de-a1f3-375e4bb43370\", \"name\": \"test_register_model\", \"status\": \"Failed\", \"start_time\": \"2020-10-26T19:30:06.502861Z\", \"created_time\": \"2020-10-26T19:24:19.286051Z\", \"end_time\": \"2020-10-26T19:32:06.4894Z\", \"duration\": \"0:07:47\", \"run_number\": 51, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-10-26T19:24:19.286051Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.16.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_run = pipeline_run.find_step_run(hd_step_name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': '3002f270-c4a2-48fe-b147-cb99ee3b1b9e',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-10-26T19:24:18.391031Z',\n",
       " 'endTimeUtc': '2020-10-26T19:24:18.509679Z',\n",
       " 'properties': {'azureml.reusedrunid': '937ccf5a-2b8b-408c-aae6-138c9f944e88',\n",
       "  'azureml.reusednodeid': 'bd3c83b3',\n",
       "  'azureml.reusedpipeline': '09a079cf-75aa-4cfd-a3d2-d3876c45c486',\n",
       "  'azureml.reusedpipelinerunid': '09a079cf-75aa-4cfd-a3d2-d3876c45c486',\n",
       "  'azureml.runsource': 'azureml.StepRun',\n",
       "  'azureml.nodeid': 'c0a88a38',\n",
       "  'ContentSnapshotId': '6d06148d-7513-4185-bb05-811c73e9edd8',\n",
       "  'StepType': 'HyperDriveStep',\n",
       "  'ComputeTargetType': 'HyperDrive',\n",
       "  'azureml.moduleid': '4cc4e7c3-bff6-4c3d-8a32-05d358bdc767',\n",
       "  'azureml.pipelinerunid': 'a142c6be-3f7b-45a2-849a-87151350cfab'},\n",
       " 'inputDatasets': [],\n",
       " 'logFiles': {'logs/azureml/executionlogs.txt': 'https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.937ccf5a-2b8b-408c-aae6-138c9f944e88/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=%2B2FNJ7lZScv2Z6ypS8u7IDqas4fsjibo9WGm5PnpIaw%3D&st=2020-10-27T03%3A17%3A42Z&se=2020-10-27T11%3A27%3A42Z&sp=r',\n",
       "  'logs/azureml/stderrlogs.txt': 'https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.937ccf5a-2b8b-408c-aae6-138c9f944e88/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=DJhAL3ec3cpQmrAi%2FgSBCtEj1ZWDX1FarseMmt8JDec%3D&st=2020-10-27T03%3A17%3A42Z&se=2020-10-27T11%3A27%3A42Z&sp=r',\n",
       "  'logs/azureml/stdoutlogs.txt': 'https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.937ccf5a-2b8b-408c-aae6-138c9f944e88/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=cEGazO4Ju%2F90hI%2BmVJqJTwPV5EYcgsjY%2B944TIPeLUY%3D&st=2020-10-27T03%3A17%3A42Z&se=2020-10-27T11%3A27%3A42Z&sp=r'}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "for step in  pipeline_run.get_steps():\n",
    "    steps.append(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Cannot find hyperdrive run from the given step run: hyper_param_training\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot find hyperdrive run from the given step run: hyper_param_training",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-cf04f463f6d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHyperDriveStepRun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_run_by_primary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/steps/hyper_drive_step.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, step_run)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find hyperdrive run from the given step run: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstep_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mmodule_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot find hyperdrive run from the given step run: hyper_param_training"
     ]
    }
   ],
   "source": [
    "HyperDriveStepRun(steps[1]).get_best_run_by_primary_metric()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-2effa117351c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhd_step_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperDriveStepRun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_step_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhd_step_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhd_step_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_run_by_primary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "hd_step_run = HyperDriveStepRun(step_run=pipeline_run.find_step_run(hd_step_name)[0])\n",
    "best_run = hd_step_run.get_best_run_by_primary_metric()\n",
    "best_run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's list the model files uploaded during the run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then register the folder (and all files in it) as a model named `sklearn-iris` under the workspace for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name='isd_model_hyper_tuned', model_path='outputs/model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run.download_file('outputs/model.joblib')"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "swatig"
   }
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Iris"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "Scikit-learn"
  ],
  "friendly_name": "Training and hyperparameter tuning with Scikit-learn",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "msauthor": "dipeck",
  "tags": [
   "None"
  ],
  "task": "Train a support vector machine (SVM) to perform classification"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
